hpcdo
=====

command line tool to ease the interaction with remote cluster and their schedulers.

## features

 - get a snapshot of available resources
 - get a list of currently running tasks
 - easily get a view of the output of currently running task (including error log)
 - easily schedule new tasks using configuration files
 - easily sync local/remote folder, update git repository on remote servers

## install

Install using pip or easy_install

    pip install hpcdo
    
    
## under the hood

The library first has a description file for the jobs which allows the user to control then using names.
The configuration file is writen in YAML and should be present in working folder. Secondly the class uses a file
to keep information about running tasks. When a task is launched, its id is stored with the associated information.
This allows to tail, delete or clear the task by name instead of using the job id.

## Notes

This python packages helps dealing with submitting jobs to the hpc and tracking them. It facilitates the wrting of
qsub script with tend to be quite obscure and repetitive. It also helps keeping track of all the files generated by a
given script. You will be able to tail, clear, or backup the output fo given run of a given job.

So a job has a description that includes a name, the type of the job (stata or julia) and also information
about where the logs should go, and the number of nodes on which the job should run. Because a given job can
be ran several time, the user will have to provide a name when running more than 1 at a time.

A command line interface is provided, but the library can also be used from inside shovel.py for example.
